This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: src/**/*.py, *.py, *.txt, *.md, *.env
- Files matching these patterns are excluded: strava_env/**, __pycache__/**, .git/**
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
src/
  app.py
  correlation_analysis.py
  exercise_sleep_analysis.py
  strava_api.py
  strava_auth.py
  test_withings.py
  token_storage.py
  withings_api.py
  withings_auth.py
jira-confluence-analyzer-todo.md
README.md
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/app.py">
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from datetime import datetime, timedelta
import os

from strava_auth import StravaAuth
from strava_api import StravaAPI
from withings_auth import WithingsAuth
from withings_api import WithingsAPI
from correlation_analysis import CorrelationAnalysis
from exercise_sleep_analysis import ExerciseSleepAnalysis
from token_storage import TokenStorage

# Page config
st.set_page_config(
    page_title="Strava Data Analyzer",
    page_icon="üèÉ",
    layout="wide"
)

# Initialize authentication and storage
auth = StravaAuth()
withings_auth = WithingsAuth()
token_storage = TokenStorage()

def main():
    st.title("üìä Health Data Analyzer")
    
    # Sidebar for navigation and authentication
    with st.sidebar:
        st.header("Navigation")
        
        # Check for authorization code first (before checking authentication)
        query_params = st.query_params
        
        # Load saved tokens on app start
        if not hasattr(st.session_state, 'tokens_loaded'):
            # Load Withings tokens
            withings_tokens = token_storage.load_tokens('withings')
            if withings_tokens:
                st.session_state.withings_access_token = withings_tokens['access_token']
                st.session_state.withings_refresh_token = withings_tokens.get('refresh_token')
            
            # Load Strava tokens
            strava_tokens = token_storage.load_tokens('strava')
            if strava_tokens:
                st.session_state.access_token = strava_tokens['access_token']
                st.session_state.refresh_token = strava_tokens.get('refresh_token')
                st.session_state.athlete_id = strava_tokens.get('athlete_id')
            
            st.session_state.tokens_loaded = True
        
        # Handle OAuth callbacks with better detection
        if 'code' in query_params:
            # Determine which service this callback is for
            if 'state' in query_params and 'scope' not in query_params:
                # Withings callback (has state but no scope)
                try:
                    code = query_params['code']
                    state = query_params['state']
                    withings_token_data = withings_auth.exchange_code_for_token(code, state)
                    
                    # Save to both session state and file
                    st.session_state.withings_access_token = withings_token_data['access_token']
                    st.session_state.withings_refresh_token = withings_token_data.get('refresh_token')
                    
                    # Save to persistent storage
                    token_storage.save_tokens('withings', withings_token_data)
                    
                    # Clear URL parameters and show success
                    st.query_params.clear()
                    st.success("Successfully connected to Withings!")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"Withings authentication failed: {str(e)}")
                    if "Rate limited" in str(e):
                        st.info("Please wait a moment before trying to connect to Withings again.")
            
            elif 'scope' in query_params:
                # Strava callback (has scope parameter)
                try:
                    code = query_params['code']
                    token_data = auth.exchange_code_for_token(code)
                    
                    # Save to both session state and file
                    st.session_state.access_token = token_data['access_token']
                    st.session_state.refresh_token = token_data.get('refresh_token')
                    st.session_state.athlete_id = token_data['athlete']['id']
                    
                    # Save to persistent storage
                    token_storage.save_tokens('strava', token_data)
                    
                    # Clear URL parameters and show success
                    st.query_params.clear()
                    st.success("Successfully authenticated with Strava!")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"Strava authentication failed: {str(e)}")
            
            else:
                # Unknown callback - clear it
                st.query_params.clear()
                st.warning("Unknown authentication callback received. Please try connecting again.")
        
        # Withings Authentication (Priority)
        st.subheader("üè• Withings Health Data")
        if not withings_auth.is_authenticated():
            st.write("Connect your Withings account first to analyze your health data.")
            
            if st.button("Connect to Withings"):
                withings_auth_url = withings_auth.get_authorization_url()
                st.markdown(f'<a href="{withings_auth_url}" target="_self">Click here to authorize Withings</a>', unsafe_allow_html=True)
        else:
            st.success("‚úÖ Connected to Withings")
            if st.button("Disconnect Withings"):
                # Clear session state
                for key in list(st.session_state.keys()):
                    if key.startswith('withings_'):
                        del st.session_state[key]
                # Clear persistent storage
                token_storage.clear_tokens('withings')
                st.rerun()
        
        # Strava Authentication (Secondary)
        st.subheader("üèÉ Strava Exercise Data")
        if not auth.is_authenticated():
            st.write("Optional: Connect Strava for exercise correlation analysis")
            
            if st.button("Connect to Strava"):
                auth_url = auth.get_authorization_url()
                st.markdown(f'<a href="{auth_url}" target="_self">Click here to authorize Strava</a>', unsafe_allow_html=True)
        else:
            st.success("‚úÖ Connected to Strava")
            if st.button("Disconnect Strava"):
                # Clear session state
                for key in list(st.session_state.keys()):
                    if key.startswith('access_token') or key.startswith('refresh_token') or key.startswith('athlete_'):
                        del st.session_state[key]
                # Clear persistent storage
                token_storage.clear_tokens('strava')
                st.rerun()
        
        # Navigation menu
        if withings_auth.is_authenticated():
            page = st.selectbox(
                "Choose a page:",
                ["Health Dashboard", "Weight Tracking", "Sleep Analysis", "Body Composition", "Exercise Analysis", "Correlation Analysis"]
            )
        else:
            page = "Welcome"
        
        # Clear authentication button for debugging
        if st.button("üîÑ Clear All & Restart"):
            st.query_params.clear()
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            # Clear all persistent storage
            token_storage.clear_tokens()
            st.rerun()
    
    # Main content area
    if withings_auth.is_authenticated():
        withings_api = WithingsAPI(withings_auth.get_access_token())
        
        if page == "Health Dashboard":
            show_health_dashboard(withings_api)
        elif page == "Weight Tracking":
            show_weight_tracking(withings_api)
        elif page == "Sleep Analysis":
            show_sleep_analysis(withings_api)
        elif page == "Body Composition":
            show_body_composition(withings_api)
        elif page == "Exercise Analysis":
            if auth.is_authenticated():
                strava_api = StravaAPI(auth.get_access_token())
                show_exercise_analysis(strava_api)
            else:
                st.warning("Connect Strava to view exercise analysis")
                st.info("You can still view health data from other pages without Strava.")
        elif page == "Correlation Analysis":
            if auth.is_authenticated():
                strava_api = StravaAPI(auth.get_access_token())
                show_correlation_analysis(strava_api)
            else:
                st.warning("Connect Strava to view correlation analysis")
                st.info("Correlation analysis requires both Withings and Strava data.")
    
    else:
        # Welcome page for unauthenticated users
        st.markdown("""
        ## Welcome to Health Data Analyzer! üè•
        
        This application helps you analyze your health and fitness data from Withings and Strava.
        
        ### üè• Withings Features:
        - ‚öñÔ∏è **Weight Tracking**: Monitor weight trends over time
        - üò¥ **Sleep Analysis**: Deep sleep, REM sleep, and sleep quality
        - ü´Ä **Body Composition**: Fat %, muscle mass, BMI, and more
        - üìä **Health Dashboard**: Comprehensive overview of your health metrics
        
        ### üèÉ Strava Features (Optional):
        - üìä **Exercise Analytics**: Distance, pace, elevation trends
        - üèÜ **Performance Metrics**: Personal records and training zones
        - üìà **Seasonal Analysis**: Year-over-year exercise patterns
        - üîó **Correlation Analysis**: How exercise affects sleep and weight
        
        ### Getting Started:
        1. **Connect to Withings** first (required for health data)
        2. **Connect to Strava** (optional, for exercise correlation)
        3. **Explore your health journey!**
        
        ---
        
        **Priority**: Start with Withings connection to see your health data immediately.
        """)

def show_health_dashboard(withings_api):
    st.header("üè• Health Dashboard")
    
    try:
        # Date range selector
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("Start Date", datetime.now() - timedelta(days=30))
        with col2:
            end_date = st.date_input("End Date", datetime.now())
        
        start_datetime = datetime.combine(start_date, datetime.min.time())
        end_datetime = datetime.combine(end_date, datetime.min.time())
        
        # Fetch all Withings data
        with st.spinner("Fetching health data..."):
            weight_data = withings_api.get_weight_measurements(start_datetime, end_datetime)
            weight_df = withings_api.weight_to_dataframe(weight_data)
            
            sleep_data = withings_api.get_sleep_data(start_datetime, end_datetime)
            sleep_df = withings_api.sleep_to_dataframe(sleep_data)
        
        # Key health metrics
        st.subheader("üìä Key Health Metrics")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if not weight_df.empty and 'weight' in weight_df.columns:
                latest_weight = weight_df['weight'].iloc[-1]
                st.metric("Current Weight", f"{latest_weight:.1f} kg")
            else:
                st.metric("Weight", "No data")
        
        with col2:
            if not weight_df.empty and 'bmi' in weight_df.columns:
                latest_bmi = weight_df['bmi'].iloc[-1]
                st.metric("BMI", f"{latest_bmi:.1f}")
            else:
                st.metric("BMI", "No data")
        
        with col3:
            if not sleep_df.empty:
                avg_sleep = sleep_df['sleep_duration'].mean()
                st.metric("Avg Sleep", f"{avg_sleep:.1f} hrs")
            else:
                st.metric("Sleep", "No data")
        
        with col4:
            if not sleep_df.empty and 'sleep_score' in sleep_df.columns:
                avg_score = sleep_df['sleep_score'].mean()
                st.metric("Sleep Score", f"{avg_score:.0f}")
            else:
                st.metric("Sleep Score", "No data")
        
        # Weight trend
        if not weight_df.empty:
            st.subheader("‚öñÔ∏è Weight Trend")
            fig_weight = px.line(
                weight_df, 
                x='date', 
                y='weight',
                title='Weight Over Time',
                labels={'weight': 'Weight (kg)', 'date': 'Date'}
            )
            st.plotly_chart(fig_weight, use_container_width=True)
        
        # Sleep overview
        if not sleep_df.empty:
            st.subheader("üò¥ Sleep Overview")
            fig_sleep = px.line(
                sleep_df,
                x='date',
                y='sleep_duration',
                title='Sleep Duration Over Time',
                labels={'sleep_duration': 'Sleep Duration (hours)', 'date': 'Date'}
            )
            st.plotly_chart(fig_sleep, use_container_width=True)
        
        if weight_df.empty and sleep_df.empty:
            st.info("No health data found for the selected date range. Try expanding the date range or check your Withings data.")
        
    except Exception as e:
        st.error(f"Error loading health dashboard: {str(e)}")

def show_weight_tracking(withings_api):
    st.header("‚öñÔ∏è Weight Tracking")
    
    try:
        # Extended date range for weight tracking
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("Start Date", datetime.now() - timedelta(days=90), key="weight_start")
        with col2:
            end_date = st.date_input("End Date", datetime.now(), key="weight_end")
        
        start_datetime = datetime.combine(start_date, datetime.min.time())
        end_datetime = datetime.combine(end_date, datetime.min.time())
        
        with st.spinner("Fetching weight data..."):
            weight_data = withings_api.get_weight_measurements(start_datetime, end_datetime)
            df = withings_api.weight_to_dataframe(weight_data)
        
        if df.empty:
            st.warning("No weight data found for the selected date range.")
            return
        
        # Weight statistics
        st.subheader("üìä Weight Statistics")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            current_weight = df['weight'].iloc[-1]
            st.metric("Current Weight", f"{current_weight:.1f} kg")
        
        with col2:
            if len(df) > 1:
                weight_change = df['weight'].iloc[-1] - df['weight'].iloc[0]
                st.metric("Weight Change", f"{weight_change:+.1f} kg")
            else:
                st.metric("Weight Change", "N/A")
        
        with col3:
            min_weight = df['weight'].min()
            st.metric("Minimum Weight", f"{min_weight:.1f} kg")
        
        with col4:
            max_weight = df['weight'].max()
            st.metric("Maximum Weight", f"{max_weight:.1f} kg")
        
        # Weight trend with moving average
        st.subheader("üìà Weight Trend Analysis")
        df['weight_ma7'] = df['weight'].rolling(window=7, center=True).mean()
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=df['date'],
            y=df['weight'],
            mode='markers',
            name='Daily Weight',
            marker=dict(color='lightblue')
        ))
        fig.add_trace(go.Scatter(
            x=df['date'],
            y=df['weight_ma7'],
            mode='lines',
            name='7-Day Moving Average',
            line=dict(color='red', width=2)
        ))
        fig.update_layout(
            title='Weight Tracking with Moving Average',
            xaxis_title='Date',
            yaxis_title='Weight (kg)',
            hovermode='x unified'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Export weight data
        st.subheader("üìÑ Export Data")
        if st.button("Export Weight Data"):
            csv = df.to_csv(index=False)
            st.download_button(
                label="Download Weight CSV",
                data=csv,
                file_name=f"weight_data_{start_date}_{end_date}.csv",
                mime="text/csv"
            )
        
    except Exception as e:
        st.error(f"Error loading weight tracking: {str(e)}")

def show_sleep_analysis(withings_api):
    st.header("üò¥ Sleep Analysis")
    
    try:
        # Date range selector
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("Start Date", datetime.now() - timedelta(days=30), key="sleep_start")
        with col2:
            end_date = st.date_input("End Date", datetime.now(), key="sleep_end")
        
        start_datetime = datetime.combine(start_date, datetime.min.time())
        end_datetime = datetime.combine(end_date, datetime.min.time())
        
        with st.spinner("Fetching sleep data..."):
            sleep_data = withings_api.get_sleep_data(start_datetime, end_datetime)
            df = withings_api.sleep_to_dataframe(sleep_data)
        
        if df.empty:
            st.warning("No sleep data found for the selected date range.")
            return
        
        # Sleep statistics
        st.subheader("üìä Sleep Statistics")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_sleep = df['sleep_duration'].mean()
            st.metric("Average Sleep", f"{avg_sleep:.1f} hrs")
        
        with col2:
            if 'deep_sleep' in df.columns:
                avg_deep = df['deep_sleep'].mean()
                st.metric("Average Deep Sleep", f"{avg_deep:.1f} hrs")
            else:
                st.metric("Deep Sleep", "No data")
        
        with col3:
            if 'rem_sleep' in df.columns:
                avg_rem = df['rem_sleep'].mean()
                st.metric("Average REM Sleep", f"{avg_rem:.1f} hrs")
            else:
                st.metric("REM Sleep", "No data")
        
        with col4:
            if 'sleep_score' in df.columns:
                avg_score = df['sleep_score'].mean()
                st.metric("Average Sleep Score", f"{avg_score:.0f}")
            else:
                st.metric("Sleep Score", "No data")
        
        # Sleep duration trend
        st.subheader("üåô Sleep Duration Trend")
        fig_duration = px.line(
            df,
            x='date',
            y='sleep_duration',
            title='Sleep Duration Over Time',
            labels={'sleep_duration': 'Sleep Duration (hours)', 'date': 'Date'}
        )
        fig_duration.add_hline(y=8, line_dash="dash", line_color="green", 
                              annotation_text="Recommended 8 hours")
        st.plotly_chart(fig_duration, use_container_width=True)
        
        # Sleep stages breakdown
        if 'deep_sleep' in df.columns and 'light_sleep' in df.columns and 'rem_sleep' in df.columns:
            st.subheader("üß† Sleep Stages Analysis")
            
            # Average sleep stages
            avg_stages = {
                'Deep Sleep': df['deep_sleep'].mean(),
                'Light Sleep': df['light_sleep'].mean(),
                'REM Sleep': df['rem_sleep'].mean()
            }
            
            fig_pie = px.pie(
                values=list(avg_stages.values()),
                names=list(avg_stages.keys()),
                title='Average Sleep Stages Distribution'
            )
            st.plotly_chart(fig_pie, use_container_width=True)
        
        # Sleep quality over time
        if 'sleep_score' in df.columns:
            st.subheader("üí§ Sleep Quality Score")
            fig_score = px.line(
                df,
                x='date',
                y='sleep_score',
                title='Sleep Quality Score Over Time',
                labels={'sleep_score': 'Sleep Score', 'date': 'Date'}
            )
            fig_score.add_hline(y=80, line_dash="dash", line_color="green", 
                               annotation_text="Good Sleep (80+)")
            st.plotly_chart(fig_score, use_container_width=True)
        
    except Exception as e:
        st.error(f"Error loading sleep analysis: {str(e)}")

def show_body_composition(withings_api):
    st.header("ü´Ä Body Composition Analysis")
    
    try:
        # Date range selector
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("Start Date", datetime.now() - timedelta(days=90), key="body_start")
        with col2:
            end_date = st.date_input("End Date", datetime.now(), key="body_end")
        
        start_datetime = datetime.combine(start_date, datetime.min.time())
        end_datetime = datetime.combine(end_date, datetime.min.time())
        
        with st.spinner("Fetching body composition data..."):
            weight_data = withings_api.get_weight_measurements(start_datetime, end_datetime)
            df = withings_api.weight_to_dataframe(weight_data)
        
        if df.empty:
            st.warning("No body composition data found for the selected date range.")
            return
        
        # Current body composition metrics
        st.subheader("üìä Current Body Composition")
        latest_data = df.iloc[-1]
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if 'fat_percent' in df.columns:
                st.metric("Body Fat %", f"{latest_data.get('fat_percent', 0):.1f}%")
            else:
                st.metric("Body Fat %", "No data")
        
        with col2:
            if 'muscle_percent' in df.columns:
                st.metric("Muscle %", f"{latest_data.get('muscle_percent', 0):.1f}%")
            else:
                st.metric("Muscle %", "No data")
        
        with col3:
            if 'bmi' in df.columns:
                st.metric("BMI", f"{latest_data.get('bmi', 0):.1f}")
            else:
                st.metric("BMI", "No data")
        
        with col4:
            if 'muscle_mass' in df.columns:
                st.metric("Muscle Mass", f"{latest_data.get('muscle_mass', 0):.1f} kg")
            else:
                st.metric("Muscle Mass", "No data")
        
        # Body composition trends
        composition_cols = ['fat_percent', 'muscle_percent', 'bone_percent']
        available_cols = [col for col in composition_cols if col in df.columns and df[col].notna().any()]
        
        if available_cols:
            st.subheader("üìà Body Composition Trends")
            fig = go.Figure()
            
            colors = ['red', 'blue', 'green']
            for i, col in enumerate(available_cols):
                fig.add_trace(go.Scatter(
                    x=df['date'],
                    y=df[col],
                    mode='lines+markers',
                    name=col.replace('_', ' ').title(),
                    line=dict(color=colors[i % len(colors)])
                ))
            
            fig.update_layout(
                title='Body Composition Over Time',
                xaxis_title='Date',
                yaxis_title='Percentage (%)',
                hovermode='x unified'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # BMI trend and categories
        if 'bmi' in df.columns:
            st.subheader("üìè BMI Analysis")
            
            fig_bmi = px.line(
                df,
                x='date',
                y='bmi',
                title='BMI Trend Over Time',
                labels={'bmi': 'BMI', 'date': 'Date'}
            )
            
            # Add BMI category lines
            fig_bmi.add_hline(y=18.5, line_dash="dash", line_color="blue", 
                             annotation_text="Underweight")
            fig_bmi.add_hline(y=25, line_dash="dash", line_color="orange", 
                             annotation_text="Overweight")
            fig_bmi.add_hline(y=30, line_dash="dash", line_color="red", 
                             annotation_text="Obese")
            
            st.plotly_chart(fig_bmi, use_container_width=True)
        
        # Body mass trends
        mass_cols = ['fat_mass', 'muscle_mass', 'bone_mass']
        available_mass_cols = [col for col in mass_cols if col in df.columns and df[col].notna().any()]
        
        if available_mass_cols:
            st.subheader("‚öñÔ∏è Body Mass Composition")
            fig_mass = go.Figure()
            
            for col in available_mass_cols:
                fig_mass.add_trace(go.Scatter(
                    x=df['date'],
                    y=df[col],
                    mode='lines+markers',
                    name=col.replace('_', ' ').title()
                ))
            
            fig_mass.update_layout(
                title='Body Mass Components Over Time',
                xaxis_title='Date',
                yaxis_title='Mass (kg)',
                hovermode='x unified'
            )
            st.plotly_chart(fig_mass, use_container_width=True)
        
    except Exception as e:
        st.error(f"Error loading body composition: {str(e)}")

def show_exercise_analysis(strava_api):
    st.header("üèÉ Exercise Analysis")
    st.info("This page shows your Strava exercise data. For correlation with health data, visit the Correlation Analysis page.")
    show_dashboard(strava_api)  # Reuse existing Strava dashboard

def show_dashboard(api):
    st.header("üìä Dashboard")
    
    try:
        # Get recent activities
        activities = api.get_activities(per_page=50)
        
        if not activities:
            st.warning("No activities found. Start recording some workouts!")
            return
        
        df = api.activities_to_dataframe(activities)
        
        # Key metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_activities = len(df)
            st.metric("Total Activities", total_activities)
        
        with col2:
            total_distance = df['distance_km'].sum()
            st.metric("Total Distance", f"{total_distance:.1f} km")
        
        with col3:
            total_time = df['moving_time_hours'].sum()
            st.metric("Total Time", f"{total_time:.1f} hours")
        
        with col4:
            avg_distance = df['distance_km'].mean()
            st.metric("Avg Distance", f"{avg_distance:.1f} km")
        
        # Get more historical data for comprehensive analysis
        all_activities = []
        page = 1
        while len(all_activities) < 1000:  # Limit to prevent too many API calls
            batch = api.get_activities(page=page, per_page=100)
            if not batch:
                break
            all_activities.extend(batch)
            page += 1
            if len(batch) < 100:  # Last page
                break
        
        if all_activities:
            all_df = api.activities_to_dataframe(all_activities)
        else:
            all_df = df
        
        # Yearly and seasonal analysis
        st.subheader("üìà Long-term Exercise Trends & Seasonal Analysis")
        
        # Add time-based columns
        all_df['year'] = all_df['start_date_local'].dt.year
        all_df['month'] = all_df['start_date_local'].dt.month
        all_df['week_of_year'] = all_df['start_date_local'].dt.isocalendar().week
        all_df['season'] = all_df['month'].map({
            1: 'Winter', 2: 'Winter', 3: 'Spring',
            4: 'Spring', 5: 'Spring', 6: 'Summer',
            7: 'Summer', 8: 'Summer', 9: 'Fall',
            10: 'Fall', 11: 'Fall', 12: 'Winter'
        })
        
        # Create comprehensive time series
        all_df['year_week'] = all_df['start_date_local'].dt.to_period('W')
        
        # Weekly aggregations for multi-year view
        weekly_comprehensive = all_df.groupby('year_week').agg({
            'distance_km': 'sum',
            'moving_time_hours': 'sum',
            'id': 'count'
        }).reset_index()
        weekly_comprehensive['date'] = weekly_comprehensive['year_week'].dt.start_time
        weekly_comprehensive['year'] = weekly_comprehensive['date'].dt.year
        weekly_comprehensive['week_num'] = weekly_comprehensive['date'].dt.isocalendar().week
        
        # Multi-year weekly exercise volume
        col1, col2 = st.columns(2)
        
        with col1:
            fig_weekly_time = px.line(
                weekly_comprehensive,
                x='date',
                y='moving_time_hours',
                title='Weekly Exercise Time Over Years',
                labels={'moving_time_hours': 'Hours per Week', 'date': 'Date'}
            )
            fig_weekly_time.add_scatter(
                x=weekly_comprehensive['date'],
                y=weekly_comprehensive['moving_time_hours'].rolling(window=4, center=True).mean(),
                mode='lines',
                name='4-week Moving Average',
                line=dict(color='red', width=2)
            )
            st.plotly_chart(fig_weekly_time, use_container_width=True)
        
        with col2:
            fig_weekly_distance = px.line(
                weekly_comprehensive,
                x='date',
                y='distance_km',
                title='Weekly Distance Over Years',
                labels={'distance_km': 'Distance (km) per Week', 'date': 'Date'}
            )
            fig_weekly_distance.add_scatter(
                x=weekly_comprehensive['date'],
                y=weekly_comprehensive['distance_km'].rolling(window=4, center=True).mean(),
                mode='lines',
                name='4-week Moving Average',
                line=dict(color='red', width=2)
            )
            st.plotly_chart(fig_weekly_distance, use_container_width=True)
        
        # Seasonal Analysis
        st.subheader("üåü Seasonal Patterns")
        
        # Seasonal aggregations
        seasonal_stats = all_df.groupby(['year', 'season']).agg({
            'distance_km': 'sum',
            'moving_time_hours': 'sum',
            'id': 'count'
        }).reset_index()
        
        # Average by season across all years
        season_avg = all_df.groupby('season').agg({
            'distance_km': 'mean',
            'moving_time_hours': 'mean',
            'id': 'count'
        }).reset_index()
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_seasonal_time = px.bar(
                season_avg,
                x='season',
                y='moving_time_hours',
                title='Average Exercise Time by Season',
                labels={'moving_time_hours': 'Avg Hours per Activity', 'season': 'Season'},
                color='season',
                category_orders={'season': ['Spring', 'Summer', 'Fall', 'Winter']}
            )
            st.plotly_chart(fig_seasonal_time, use_container_width=True)
        
        with col2:
            fig_seasonal_distance = px.bar(
                season_avg,
                x='season',
                y='distance_km',
                title='Average Distance by Season',
                labels={'distance_km': 'Avg Distance (km) per Activity', 'season': 'Season'},
                color='season',
                category_orders={'season': ['Spring', 'Summer', 'Fall', 'Winter']}
            )
            st.plotly_chart(fig_seasonal_distance, use_container_width=True)
        
        # Yearly trends
        st.subheader("üìä Year-over-Year Trends")
        
        yearly_stats = all_df.groupby('year').agg({
            'distance_km': 'sum',
            'moving_time_hours': 'sum',
            'id': 'count'
        }).reset_index()
        
        if len(yearly_stats) > 1:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                fig_yearly_total = px.bar(
                    yearly_stats,
                    x='year',
                    y='moving_time_hours',
                    title='Total Exercise Hours by Year',
                    labels={'moving_time_hours': 'Total Hours', 'year': 'Year'}
                )
                st.plotly_chart(fig_yearly_total, use_container_width=True)
            
            with col2:
                fig_yearly_distance = px.bar(
                    yearly_stats,
                    x='year',
                    y='distance_km',
                    title='Total Distance by Year',
                    labels={'distance_km': 'Total Distance (km)', 'year': 'Year'}
                )
                st.plotly_chart(fig_yearly_distance, use_container_width=True)
            
            with col3:
                fig_yearly_activities = px.bar(
                    yearly_stats,
                    x='year',
                    y='id',
                    title='Total Activities by Year',
                    labels={'id': 'Number of Activities', 'year': 'Year'}
                )
                st.plotly_chart(fig_yearly_activities, use_container_width=True)
        
        # Heatmap of weekly patterns
        st.subheader("üî• Exercise Intensity Heatmap")
        
        # Create a heatmap showing exercise volume by week of year across years
        if len(weekly_comprehensive) > 52:
            # Pivot data for heatmap
            heatmap_data = weekly_comprehensive.pivot_table(
                index='year',
                columns='week_num',
                values='moving_time_hours',
                fill_value=0
            )
            
            fig_heatmap = px.imshow(
                heatmap_data,
                title='Exercise Hours by Week Across Years',
                labels={'x': 'Week of Year', 'y': 'Year', 'color': 'Hours'},
                aspect='auto'
            )
            st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # Activity type distribution
        st.subheader("üèÉ Activity Types")
        activity_counts = all_df['type'].value_counts()
        
        fig_pie = px.pie(
            values=activity_counts.values,
            names=activity_counts.index,
            title='Activity Distribution (All Time)'
        )
        st.plotly_chart(fig_pie, use_container_width=True)
        
    except Exception as e:
        st.error(f"Error loading dashboard: {str(e)}")

def show_activities(api):
    st.header("üèÉ Activities")
    
    try:
        # Date filter
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("Start Date", datetime.now() - timedelta(days=30))
        with col2:
            end_date = st.date_input("End Date", datetime.now())
        
        # Get activities
        activities = api.get_activities(
            after=datetime.combine(start_date, datetime.min.time()),
            before=datetime.combine(end_date, datetime.min.time()),
            per_page=100
        )
        
        if not activities:
            st.warning("No activities found for the selected date range.")
            return
        
        df = api.activities_to_dataframe(activities)
        
        # Activity table
        st.subheader("Recent Activities")
        
        # Select columns to display
        display_columns = [
            'name', 'type', 'start_date_local', 'distance_km', 
            'moving_time_hours', 'total_elevation_gain'
        ]
        
        display_df = df[display_columns].copy()
        display_df['start_date_local'] = display_df['start_date_local'].dt.strftime('%Y-%m-%d %H:%M')
        display_df = display_df.round(2)
        
        st.dataframe(
            display_df,
            column_config={
                "name": "Activity Name",
                "type": "Type",
                "start_date_local": "Date",
                "distance_km": "Distance (km)",
                "moving_time_hours": "Time (hours)",
                "total_elevation_gain": "Elevation (m)"
            },
            use_container_width=True
        )
        
        # Export functionality
        if st.button("Export to CSV"):
            csv = df.to_csv(index=False)
            st.download_button(
                label="Download CSV",
                data=csv,
                file_name=f"strava_activities_{start_date}_{end_date}.csv",
                mime="text/csv"
            )
        
    except Exception as e:
        st.error(f"Error loading activities: {str(e)}")

def show_performance_analytics(api):
    st.header("üèÜ Performance Analytics")
    st.info("Performance analytics coming soon! This will include personal records, training zones, and improvement trends.")

def show_profile(api):
    st.header("üë§ Athlete Profile")
    
    try:
        athlete = api.get_athlete()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Basic Info")
            st.write(f"**Name:** {athlete.get('firstname', '')} {athlete.get('lastname', '')}")
            st.write(f"**Location:** {athlete.get('city', 'Not specified')}, {athlete.get('country', '')}")
            st.write(f"**Member Since:** {athlete.get('created_at', 'Unknown')[:10]}")
            
        with col2:
            st.subheader("Stats")
            if 'follower_count' in athlete:
                st.write(f"**Followers:** {athlete['follower_count']}")
            if 'friend_count' in athlete:
                st.write(f"**Following:** {athlete['friend_count']}")
        
        # Get athlete stats if available
        try:
            stats = api.get_athlete_stats(athlete['id'])
            
            st.subheader("All-Time Stats")
            
            col1, col2, col3 = st.columns(3)
            
            if 'all_run_totals' in stats:
                with col1:
                    st.metric(
                        "Total Run Distance", 
                        f"{stats['all_run_totals']['distance'] / 1000:.0f} km"
                    )
                    st.metric(
                        "Total Run Time", 
                        f"{stats['all_run_totals']['moving_time'] / 3600:.0f} hours"
                    )
            
            if 'all_ride_totals' in stats:
                with col2:
                    st.metric(
                        "Total Ride Distance", 
                        f"{stats['all_ride_totals']['distance'] / 1000:.0f} km"
                    )
                    st.metric(
                        "Total Ride Time", 
                        f"{stats['all_ride_totals']['moving_time'] / 3600:.0f} hours"
                    )
            
        except Exception as e:
            st.warning("Could not load detailed stats.")
        
    except Exception as e:
        st.error(f"Error loading profile: {str(e)}")

def show_correlation_analysis(strava_api):
    st.header("üìà Exercise, Sleep & Weight Correlation Analysis")
    
    if not withings_auth.is_authenticated():
        st.warning("Please connect your Withings account to analyze correlations with weight and sleep data.")
        return
    
    try:
        withings_api = WithingsAPI(withings_auth.get_access_token())
        analyzer = CorrelationAnalysis()
        exercise_sleep_analyzer = ExerciseSleepAnalysis()
        
        # Date range selector
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("Start Date", datetime.now() - timedelta(days=90))
        with col2:
            end_date = st.date_input("End Date", datetime.now())
        
        start_datetime = datetime.combine(start_date, datetime.min.time())
        end_datetime = datetime.combine(end_date, datetime.min.time())
        
        # Fetch data
        with st.spinner("Fetching data from Strava and Withings..."):
            # Strava data
            strava_activities = strava_api.get_activities(
                after=start_datetime,
                before=end_datetime,
                per_page=200
            )
            strava_df = strava_api.activities_to_dataframe(strava_activities) if strava_activities else pd.DataFrame()
            
            # Withings data
            weight_data = withings_api.get_weight_measurements(start_datetime, end_datetime)
            weight_df = withings_api.weight_to_dataframe(weight_data)
            
            sleep_data = withings_api.get_sleep_data(start_datetime, end_datetime)
            sleep_df = withings_api.sleep_to_dataframe(sleep_data)
        
        # ===============================
        # NEW: Advanced Exercise-Sleep Analysis
        # ===============================
        
        st.subheader("üéØ Exercise Impact on Sleep Quality (Advanced Analysis)")
        st.info("This analysis examines how exercise timing and intensity affect your sleep over the next 1-2 nights, using machine learning models.")
        
        if not strava_df.empty and not sleep_df.empty:
            # Prepare exercise-sleep impact data
            exercise_sleep_df = exercise_sleep_analyzer.prepare_exercise_sleep_data(strava_df, sleep_df)
            
            if not exercise_sleep_df.empty and len(exercise_sleep_df) > 5:
                # Perform regression analysis
                regression_results = exercise_sleep_analyzer.perform_regression_analysis(exercise_sleep_df)
                
                # Analyze timing effects
                timing_analysis = exercise_sleep_analyzer.analyze_exercise_timing_effects(exercise_sleep_df)
                
                # Generate insights
                st.subheader("üß† Key Insights: Exercise ‚Üí Sleep Impact")
                insights = exercise_sleep_analyzer.generate_insights(exercise_sleep_df, regression_results, timing_analysis)
                for insight in insights:
                    st.markdown(insight)
                
                # Exercise timing visualization
                timing_plot = exercise_sleep_analyzer.create_exercise_timing_plot(exercise_sleep_df)
                if timing_plot:
                    st.plotly_chart(timing_plot, use_container_width=True)
                
                # Scatter plots for exercise-sleep relationships
                scatter_plots = exercise_sleep_analyzer.create_exercise_sleep_scatter(exercise_sleep_df)
                for plot in scatter_plots:
                    st.plotly_chart(plot, use_container_width=True)
                
                # Model performance summary
                if regression_results:
                    st.subheader("üî¨ Model Performance Summary")
                    
                    model_data = []
                    for target, results in regression_results.items():
                        model_data.append({
                            'Sleep Metric': target.replace('night1_', 'Night 1: ').replace('night2_', 'Night 2: ').replace('_', ' ').title(),
                            'Linear R¬≤': f"{results['linear_r2']:.3f}",
                            'Random Forest R¬≤': f"{results['rf_r2']:.3f}",
                            'Sample Size': results['sample_size'],
                            'Top Factor': max(results['feature_importance'].keys(), key=lambda x: results['feature_importance'][x]).replace('_', ' ').title()
                        })
                    
                    model_df = pd.DataFrame(model_data)
                    st.dataframe(model_df, use_container_width=True)
                
                # Export exercise-sleep analysis
                st.subheader("üìÑ Export Exercise-Sleep Analysis")
                if st.button("Export Exercise-Sleep Data"):
                    csv = exercise_sleep_df.to_csv(index=False)
                    st.download_button(
                        label="Download Exercise-Sleep Analysis CSV",
                        data=csv,
                        file_name=f"exercise_sleep_analysis_{start_date}_{end_date}.csv",
                        mime="text/csv"
                    )
            else:
                st.warning("Insufficient data for advanced exercise-sleep analysis. Need at least 5 exercise sessions with corresponding sleep data.")
        else:
            st.warning("Need both exercise and sleep data for advanced analysis.")
        
        # ===============================
        # EXISTING: General Correlations
        # ===============================
        
        st.subheader("üìä General Health Correlations")
        
        # Combine data
        combined_df = analyzer.prepare_combined_data(strava_df, weight_df, sleep_df)
        
        if combined_df.empty:
            st.warning("No overlapping data found between Strava and Withings for the selected date range.")
            return
        
        # Display data summary
        col1, col2, col3 = st.columns(3)
        
        with col1:
            exercise_days = combined_df['daily_exercise_time'].notna().sum() if 'daily_exercise_time' in combined_df.columns else 0
            st.metric("Exercise Days", exercise_days)
        
        with col2:
            weight_measurements = combined_df['weight'].notna().sum() if 'weight' in combined_df.columns else 0
            st.metric("Weight Measurements", weight_measurements)
        
        with col3:
            sleep_days = combined_df['sleep_duration'].notna().sum() if 'sleep_duration' in combined_df.columns else 0
            st.metric("Sleep Records", sleep_days)
        
        # Calculate correlations
        correlations = analyzer.calculate_correlations(combined_df)
        
        # Display correlation insights
        insights = analyzer.generate_insights(correlations, combined_df)
        for insight in insights:
            st.write(insight)
        
        # Correlation matrix
        correlation_matrix_fig = analyzer.create_correlation_matrix(combined_df)
        if correlation_matrix_fig:
            st.plotly_chart(correlation_matrix_fig, use_container_width=True)
        else:
            st.info("Not enough data for correlation matrix visualization.")
        
        # Time series comparison
        time_series_fig = analyzer.create_time_series_comparison(combined_df)
        if time_series_fig:
            st.plotly_chart(time_series_fig, use_container_width=True)
        else:
            st.info("Not enough data for time series comparison.")
        
        # Scatter plots
        scatter_plots = analyzer.create_scatter_plots(combined_df)
        
        if scatter_plots:
            for i, fig in enumerate(scatter_plots):
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Not enough data for scatter plot analysis.")
        
        # Raw data display (optional)
        with st.expander("üîç View Raw Combined Data"):
            st.dataframe(combined_df, use_container_width=True)
    
    except Exception as e:
        st.error(f"Error in correlation analysis: {str(e)}")
        st.error("Make sure both Strava and Withings are properly connected.")

if __name__ == "__main__":
    main()
</file>

<file path="src/correlation_analysis.py">
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
from scipy import stats
from datetime import datetime, timedelta

class CorrelationAnalysis:
    def __init__(self):
        pass
    
    def prepare_combined_data(self, strava_df, withings_weight_df, withings_sleep_df):
        """Combine and align data from different sources by date"""
        # Prepare Strava data (daily aggregation)
        if not strava_df.empty:
            strava_daily = strava_df.groupby(strava_df['start_date_local'].dt.date).agg({
                'distance_km': 'sum',
                'moving_time_hours': 'sum',
                'total_elevation_gain': 'sum',
                'id': 'count'
            }).reset_index()
            strava_daily.columns = ['date', 'daily_distance', 'daily_exercise_time', 'daily_elevation', 'daily_activities']
            strava_daily['date'] = pd.to_datetime(strava_daily['date'])
        else:
            strava_daily = pd.DataFrame()
        
        # Prepare weight data (daily - take most recent measurement per day)
        if not withings_weight_df.empty:
            weight_daily = withings_weight_df.copy()
            weight_daily['date_key'] = weight_daily['date'].dt.date
            weight_daily = weight_daily.groupby('date_key').last().reset_index()
            weight_daily['date'] = pd.to_datetime(weight_daily['date_key'])
            weight_daily = weight_daily.drop('date_key', axis=1)
        else:
            weight_daily = pd.DataFrame()
        
        # Prepare sleep data (daily)
        if not withings_sleep_df.empty:
            sleep_daily = withings_sleep_df.copy()
            sleep_daily['date_key'] = sleep_daily['date'].dt.date
            
            # Aggregate sleep data by date
            sleep_agg = sleep_daily.groupby('date_key').agg({
                'sleep_duration': 'sum',
                'deep_sleep': 'sum',
                'light_sleep': 'sum', 
                'rem_sleep': 'sum',
                'sleep_score': 'mean'
            }).reset_index()
            
            sleep_agg['date'] = pd.to_datetime(sleep_agg['date_key'])
            sleep_daily = sleep_agg.drop('date_key', axis=1)
        else:
            sleep_daily = pd.DataFrame()
        
        # Merge all data systematically
        all_dataframes = []
        
        if not strava_daily.empty:
            all_dataframes.append(strava_daily)
        if not weight_daily.empty:
            all_dataframes.append(weight_daily)
        if not sleep_daily.empty:
            all_dataframes.append(sleep_daily)
        
        if not all_dataframes:
            return pd.DataFrame()
        
        # Start with first dataframe and merge others
        combined_df = all_dataframes[0].copy()
        
        for df in all_dataframes[1:]:
            combined_df = pd.merge(combined_df, df, on='date', how='outer', suffixes=('', '_duplicate'))
            
            # Remove duplicate columns that might have been created
            duplicate_cols = [col for col in combined_df.columns if col.endswith('_duplicate')]
            combined_df = combined_df.drop(columns=duplicate_cols)
        
        # Sort by date and fill forward for weight (since weight changes gradually)
        if not combined_df.empty:
            combined_df = combined_df.sort_values('date')
            if 'weight' in combined_df.columns:
                combined_df['weight'] = combined_df['weight'].fillna(method='ffill')
        
        return combined_df
    
    def calculate_correlations(self, df):
        """Calculate correlation coefficients between different metrics"""
        if df.empty:
            return {}
        
        correlations = {}
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        
        # Define interesting correlation pairs
        correlation_pairs = [
            ('daily_exercise_time', 'weight'),
            ('daily_exercise_time', 'sleep_duration'),
            ('daily_exercise_time', 'deep_sleep'),
            ('daily_exercise_time', 'sleep_score'),
            ('daily_distance', 'weight'),
            ('daily_distance', 'sleep_duration'),
            ('sleep_duration', 'weight'),
            ('deep_sleep', 'weight'),
            ('sleep_score', 'weight'),
            ('daily_activities', 'sleep_duration'),
            ('daily_elevation', 'sleep_duration')
        ]
        
        for col1, col2 in correlation_pairs:
            if col1 in numeric_columns and col2 in numeric_columns:
                # Remove rows where either value is NaN
                valid_data = df[[col1, col2]].dropna()
                if len(valid_data) > 10:  # Need at least 10 data points
                    correlation, p_value = stats.pearsonr(valid_data[col1], valid_data[col2])
                    correlations[f"{col1}_vs_{col2}"] = {
                        'correlation': correlation,
                        'p_value': p_value,
                        'sample_size': len(valid_data),
                        'significant': p_value < 0.05
                    }
        
        return correlations
    
    def create_correlation_matrix(self, df):
        """Create correlation matrix visualization"""
        if df.empty:
            return None
        
        # Select numeric columns for correlation matrix
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        # Filter out columns with too many NaN values
        valid_cols = []
        for col in numeric_cols:
            if df[col].count() / len(df) > 0.3:  # At least 30% non-null values
                valid_cols.append(col)
        
        if len(valid_cols) < 2:
            return None
        
        correlation_matrix = df[valid_cols].corr()
        
        fig = px.imshow(
            correlation_matrix,
            title='Correlation Matrix: Exercise, Sleep & Weight',
            labels={'color': 'Correlation Coefficient'},
            color_continuous_scale='RdBu',
            aspect='auto'
        )
        
        return fig
    
    def create_time_series_comparison(self, df):
        """Create time series plots comparing different metrics"""
        if df.empty:
            return None
        
        # Create subplots
        fig = make_subplots(
            rows=3, cols=1,
            subplot_titles=['Exercise Time vs Weight', 'Sleep Duration vs Weight', 'Exercise vs Sleep'],
            shared_xaxes=True
        )
        
        # Plot 1: Exercise Time vs Weight
        if 'daily_exercise_time' in df.columns and 'weight' in df.columns:
            # Exercise time
            fig.add_trace(
                go.Scatter(
                    x=df['date'],
                    y=df['daily_exercise_time'],
                    name='Exercise Time (hrs)',
                    line=dict(color='blue'),
                    yaxis='y1'
                ),
                row=1, col=1
            )
            
            # Weight (on secondary y-axis)
            fig.add_trace(
                go.Scatter(
                    x=df['date'],
                    y=df['weight'],
                    name='Weight (kg)',
                    line=dict(color='red'),
                    yaxis='y2'
                ),
                row=1, col=1
            )
        
        # Plot 2: Sleep Duration vs Weight
        if 'sleep_duration' in df.columns and 'weight' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df['date'],
                    y=df['sleep_duration'],
                    name='Sleep Duration (hrs)',
                    line=dict(color='green'),
                    yaxis='y3'
                ),
                row=2, col=1
            )
            
            fig.add_trace(
                go.Scatter(
                    x=df['date'],
                    y=df['weight'],
                    name='Weight (kg)',
                    line=dict(color='red'),
                    yaxis='y4',
                    showlegend=False
                ),
                row=2, col=1
            )
        
        # Plot 3: Exercise vs Sleep
        if 'daily_exercise_time' in df.columns and 'sleep_duration' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df['date'],
                    y=df['daily_exercise_time'],
                    name='Exercise Time (hrs)',
                    line=dict(color='blue'),
                    yaxis='y5',
                    showlegend=False
                ),
                row=3, col=1
            )
            
            fig.add_trace(
                go.Scatter(
                    x=df['date'],
                    y=df['sleep_duration'],
                    name='Sleep Duration (hrs)',
                    line=dict(color='green'),
                    yaxis='y6',
                    showlegend=False
                ),
                row=3, col=1
            )
        
        fig.update_layout(
            height=800,
            title_text="Time Series Comparison of Exercise, Sleep & Weight"
        )
        
        return fig
    
    def create_scatter_plots(self, df):
        """Create scatter plots for key correlations"""
        if df.empty:
            return []
        
        plots = []
        
        # Exercise vs Weight
        if 'daily_exercise_time' in df.columns and 'weight' in df.columns:
            clean_data = df[['daily_exercise_time', 'weight']].dropna()
            if len(clean_data) > 5:
                fig = px.scatter(
                    clean_data,
                    x='daily_exercise_time',
                    y='weight',
                    title='Exercise Time vs Weight',
                    labels={'daily_exercise_time': 'Daily Exercise Time (hours)', 'weight': 'Weight (kg)'},
                    trendline='ols'
                )
                plots.append(fig)
        
        # Sleep vs Weight
        if 'sleep_duration' in df.columns and 'weight' in df.columns:
            clean_data = df[['sleep_duration', 'weight']].dropna()
            if len(clean_data) > 5:
                fig = px.scatter(
                    clean_data,
                    x='sleep_duration',
                    y='weight',
                    title='Sleep Duration vs Weight',
                    labels={'sleep_duration': 'Sleep Duration (hours)', 'weight': 'Weight (kg)'},
                    trendline='ols'
                )
                plots.append(fig)
        
        # Exercise vs Sleep
        if 'daily_exercise_time' in df.columns and 'sleep_duration' in df.columns:
            clean_data = df[['daily_exercise_time', 'sleep_duration']].dropna()
            if len(clean_data) > 5:
                fig = px.scatter(
                    clean_data,
                    x='daily_exercise_time',
                    y='sleep_duration',
                    title='Exercise Time vs Sleep Duration',
                    labels={'daily_exercise_time': 'Daily Exercise Time (hours)', 'sleep_duration': 'Sleep Duration (hours)'},
                    trendline='ols'
                )
                plots.append(fig)
        
        return plots
    
    def generate_insights(self, correlations, df):
        """Generate text insights from correlation analysis"""
        insights = []
        
        if not correlations:
            insights.append("Not enough data available for correlation analysis.")
            return insights
        
        # Analyze significant correlations
        significant_correlations = {k: v for k, v in correlations.items() if v['significant']}
        
        if significant_correlations:
            insights.append("**Significant Correlations Found:**")
            
            for name, stats in significant_correlations.items():
                correlation = stats['correlation']
                col1, col2 = name.replace('_vs_', ' and ').replace('_', ' ').title().split(' And ')
                
                if abs(correlation) > 0.5:
                    strength = "strong"
                elif abs(correlation) > 0.3:
                    strength = "moderate"
                else:
                    strength = "weak"
                
                direction = "positive" if correlation > 0 else "negative"
                
                insights.append(f"- {col1} and {col2}: {strength} {direction} correlation ({correlation:.3f})")
        
        # Data availability insights
        if not df.empty:
            insights.append("\n**Data Availability:**")
            if 'daily_exercise_time' in df.columns:
                exercise_days = df['daily_exercise_time'].notna().sum()
                insights.append(f"- Exercise data: {exercise_days} days")
            
            if 'weight' in df.columns:
                weight_measurements = df['weight'].notna().sum()
                insights.append(f"- Weight measurements: {weight_measurements} days")
            
            if 'sleep_duration' in df.columns:
                sleep_days = df['sleep_duration'].notna().sum()
                insights.append(f"- Sleep data: {sleep_days} days")
        
        return insights
</file>

<file path="src/exercise_sleep_analysis.py">
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
from scipy import stats
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Try to import sklearn components with fallback
try:
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import r2_score, mean_absolute_error
    SKLEARN_AVAILABLE = True
except ImportError as e:
    SKLEARN_AVAILABLE = False
    print(f"Sklearn not available: {e}")

# Alternative simple implementations if sklearn fails
class SimpleLinearRegression:
    def __init__(self):
        self.coef_ = None
        self.intercept_ = None
    
    def fit(self, X, y):
        X = np.array(X)
        y = np.array(y)
        
        if X.ndim == 1:
            X = X.reshape(-1, 1)
        
        # Add intercept column
        X_with_intercept = np.column_stack([np.ones(X.shape[0]), X])
        
        # Normal equation: (X'X)^-1 X'y
        try:
            coefficients = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ y
            self.intercept_ = coefficients[0]
            self.coef_ = coefficients[1:]
        except:
            self.intercept_ = 0
            self.coef_ = np.zeros(X.shape[1])
    
    def predict(self, X):
        X = np.array(X)
        if X.ndim == 1:
            X = X.reshape(-1, 1)
        return self.intercept_ + X @ self.coef_

def simple_r2_score(y_true, y_pred):
    """Simple R¬≤ calculation"""
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    
    ss_res = np.sum((y_true - y_pred) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    
    if ss_tot == 0:
        return 0
    
    return 1 - (ss_res / ss_tot)

class ExerciseSleepAnalysis:
    def __init__(self):
        if SKLEARN_AVAILABLE:
            self.scaler = StandardScaler()
        else:
            self.scaler = None
    
    def prepare_exercise_sleep_data(self, strava_df, sleep_df):
        """Prepare data for exercise-sleep impact analysis"""
        if strava_df.empty or sleep_df.empty:
            return pd.DataFrame()
        
        # Prepare exercise data with timing
        exercise_data = strava_df.copy()
        exercise_data['exercise_date'] = exercise_data['start_date_local'].dt.date
        exercise_data['exercise_hour'] = exercise_data['start_date_local'].dt.hour
        exercise_data['exercise_time_category'] = exercise_data['exercise_hour'].apply(self._categorize_exercise_time)
        
        # Daily exercise aggregation
        daily_exercise = exercise_data.groupby('exercise_date').agg({
            'moving_time_hours': 'sum',
            'distance_km': 'sum',
            'total_elevation_gain': 'sum',
            'exercise_hour': ['mean', 'min', 'max'],  # Average and range of exercise times
            'exercise_time_category': lambda x: x.mode().iloc[0] if not x.empty else 'None'
        }).reset_index()
        
        # Flatten column names
        daily_exercise.columns = ['exercise_date', 'total_exercise_time', 'total_distance', 
                                'total_elevation', 'avg_exercise_hour', 'earliest_exercise', 
                                'latest_exercise', 'primary_exercise_time']
        
        # Prepare sleep data
        sleep_data = sleep_df.copy()
        sleep_data['sleep_date'] = sleep_data['date'].dt.date
        
        # Create features for next-day and two-day sleep analysis
        analysis_data = []
        
        for idx, exercise_row in daily_exercise.iterrows():
            exercise_date = exercise_row['exercise_date']
            
            # Find sleep data for next 1-2 nights
            night1_date = exercise_date + timedelta(days=1)
            night2_date = exercise_date + timedelta(days=2)
            
            night1_sleep = sleep_data[sleep_data['sleep_date'] == night1_date]
            night2_sleep = sleep_data[sleep_data['sleep_date'] == night2_date]
            
            # Create record with exercise and subsequent sleep data
            record = {
                'exercise_date': exercise_date,
                'total_exercise_time': exercise_row['total_exercise_time'],
                'total_distance': exercise_row['total_distance'],
                'total_elevation': exercise_row['total_elevation'],
                'avg_exercise_hour': exercise_row['avg_exercise_hour'],
                'earliest_exercise': exercise_row['earliest_exercise'],
                'latest_exercise': exercise_row['latest_exercise'],
                'primary_exercise_time': exercise_row['primary_exercise_time'],
                'exercise_intensity': self._calculate_intensity(exercise_row)
            }
            
            # Night 1 sleep (night after exercise)
            if not night1_sleep.empty:
                night1 = night1_sleep.iloc[0]
                record.update({
                    'night1_sleep_duration': night1.get('sleep_duration', np.nan),
                    'night1_deep_sleep': night1.get('deep_sleep', np.nan),
                    'night1_rem_sleep': night1.get('rem_sleep', np.nan),
                    'night1_sleep_score': night1.get('sleep_score', np.nan),
                    'night1_sleep_efficiency': self._calculate_sleep_efficiency(night1)
                })
            else:
                record.update({
                    'night1_sleep_duration': np.nan,
                    'night1_deep_sleep': np.nan,
                    'night1_rem_sleep': np.nan,
                    'night1_sleep_score': np.nan,
                    'night1_sleep_efficiency': np.nan
                })
            
            # Night 2 sleep (second night after exercise)
            if not night2_sleep.empty:
                night2 = night2_sleep.iloc[0]
                record.update({
                    'night2_sleep_duration': night2.get('sleep_duration', np.nan),
                    'night2_deep_sleep': night2.get('deep_sleep', np.nan),
                    'night2_rem_sleep': night2.get('rem_sleep', np.nan),
                    'night2_sleep_score': night2.get('sleep_score', np.nan),
                    'night2_sleep_efficiency': self._calculate_sleep_efficiency(night2)
                })
            else:
                record.update({
                    'night2_sleep_duration': np.nan,
                    'night2_deep_sleep': np.nan,
                    'night2_rem_sleep': np.nan,
                    'night2_sleep_score': np.nan,
                    'night2_sleep_efficiency': np.nan
                })
            
            analysis_data.append(record)
        
        df = pd.DataFrame(analysis_data)
        
        # Add baseline sleep metrics (average sleep when no exercise previous day)
        df = self._add_baseline_sleep_metrics(df, sleep_data)
        
        return df
    
    def _categorize_exercise_time(self, hour):
        """Categorize exercise time into periods"""
        if 5 <= hour < 10:
            return 'Early Morning'
        elif 10 <= hour < 14:
            return 'Late Morning'
        elif 14 <= hour < 18:
            return 'Afternoon'
        elif 18 <= hour < 22:
            return 'Evening'
        else:
            return 'Night'
    
    def _calculate_intensity(self, exercise_row):
        """Calculate exercise intensity score"""
        # Normalize metrics and combine
        time_factor = min(exercise_row['total_exercise_time'] / 2.0, 1.0)  # Cap at 2 hours
        distance_factor = min(exercise_row['total_distance'] / 20.0, 1.0)  # Cap at 20km
        elevation_factor = min(exercise_row['total_elevation'] / 1000.0, 1.0)  # Cap at 1000m
        
        return (time_factor + distance_factor + elevation_factor) / 3.0
    
    def _calculate_sleep_efficiency(self, sleep_row):
        """Calculate sleep efficiency metric"""
        if pd.isna(sleep_row.get('sleep_duration')) or sleep_row.get('sleep_duration', 0) == 0:
            return np.nan
        
        deep_sleep = sleep_row.get('deep_sleep', 0)
        rem_sleep = sleep_row.get('rem_sleep', 0)
        total_sleep = sleep_row.get('sleep_duration', 1)
        
        # Efficiency = (deep + REM) / total sleep time
        return (deep_sleep + rem_sleep) / total_sleep if total_sleep > 0 else np.nan
    
    def _add_baseline_sleep_metrics(self, df, sleep_data):
        """Add baseline sleep metrics for comparison"""
        # Calculate average sleep metrics for baseline
        baseline_metrics = {
            'baseline_sleep_duration': sleep_data['sleep_duration'].mean(),
            'baseline_deep_sleep': sleep_data['deep_sleep'].mean(),
            'baseline_rem_sleep': sleep_data['rem_sleep'].mean(),
            'baseline_sleep_score': sleep_data['sleep_score'].mean()
        }
        
        for metric, value in baseline_metrics.items():
            df[metric] = value
        
        return df
    
    def perform_regression_analysis(self, df):
        """Perform multiple regression analyses"""
        results = {}
        
        # Define target variables (sleep outcomes)
        sleep_targets = ['night1_sleep_duration', 'night1_deep_sleep', 'night1_sleep_score',
                        'night2_sleep_duration', 'night2_deep_sleep', 'night2_sleep_score']
        
        # Define predictor variables
        predictors = ['total_exercise_time', 'total_distance', 'exercise_intensity', 'avg_exercise_hour']
        
        for target in sleep_targets:
            if target in df.columns:
                # Prepare data (remove NaN values)
                analysis_df = df[predictors + [target]].dropna()
                
                if len(analysis_df) > 10:  # Need sufficient data
                    X = analysis_df[predictors]
                    y = analysis_df[target]
                    
                    try:
                        if SKLEARN_AVAILABLE:
                            # Linear regression with sklearn
                            lr_model = LinearRegression()
                            lr_model.fit(X, y)
                            lr_predictions = lr_model.predict(X)
                            lr_r2 = r2_score(y, lr_predictions)
                            
                            # Random Forest for non-linear relationships
                            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
                            rf_model.fit(X, y)
                            rf_predictions = rf_model.predict(X)
                            rf_r2 = r2_score(y, rf_predictions)
                            
                            results[target] = {
                                'linear_r2': lr_r2,
                                'rf_r2': rf_r2,
                                'linear_coefficients': dict(zip(predictors, lr_model.coef_)),
                                'feature_importance': dict(zip(predictors, rf_model.feature_importances_)),
                                'sample_size': len(analysis_df)
                            }
                        else:
                            # Fallback to simple linear regression
                            lr_model = SimpleLinearRegression()
                            lr_model.fit(X, y)
                            lr_predictions = lr_model.predict(X)
                            lr_r2 = simple_r2_score(y, lr_predictions)
                            
                            # Simple feature importance (correlation-based)
                            feature_importance = {}
                            for predictor in predictors:
                                corr = np.corrcoef(X[predictor], y)[0, 1]
                                feature_importance[predictor] = abs(corr) if not np.isnan(corr) else 0
                            
                            results[target] = {
                                'linear_r2': lr_r2,
                                'rf_r2': lr_r2,  # Use same as linear for fallback
                                'linear_coefficients': dict(zip(predictors, lr_model.coef_)),
                                'feature_importance': feature_importance,
                                'sample_size': len(analysis_df)
                            }
                    except Exception as e:
                        print(f"Error in regression for {target}: {e}")
                        continue
        
        return results
    
    def analyze_exercise_timing_effects(self, df):
        """Analyze how exercise timing affects sleep"""
        timing_analysis = {}
        
        # Group by exercise time category
        time_categories = ['Early Morning', 'Late Morning', 'Afternoon', 'Evening', 'Night']
        sleep_metrics = ['night1_sleep_duration', 'night1_deep_sleep', 'night1_sleep_score']
        
        for metric in sleep_metrics:
            if metric in df.columns:
                category_effects = {}
                
                for category in time_categories:
                    category_data = df[df['primary_exercise_time'] == category][metric].dropna()
                    baseline = df[f'baseline_{metric.replace("night1_", "")}'].iloc[0] if len(df) > 0 else np.nan
                    
                    if len(category_data) > 2:
                        mean_sleep = category_data.mean()
                        effect_size = mean_sleep - baseline if not pd.isna(baseline) else np.nan
                        
                        category_effects[category] = {
                            'mean': mean_sleep,
                            'count': len(category_data),
                            'effect_size': effect_size,
                            'std': category_data.std()
                        }
                
                timing_analysis[metric] = category_effects
        
        return timing_analysis
    
    def create_exercise_timing_plot(self, df):
        """Create visualization of exercise timing effects"""
        if df.empty:
            return None
        
        # Calculate average sleep metrics by exercise time
        timing_summary = df.groupby('primary_exercise_time').agg({
            'night1_sleep_duration': 'mean',
            'night1_deep_sleep': 'mean',
            'night1_sleep_score': 'mean',
            'total_exercise_time': 'count'
        }).reset_index()
        
        timing_summary = timing_summary[timing_summary['total_exercise_time'] >= 3]  # At least 3 observations
        
        if timing_summary.empty:
            return None
        
        # Create subplot with multiple metrics
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=['Sleep Duration by Exercise Timing', 'Deep Sleep by Exercise Timing',
                          'Sleep Score by Exercise Timing', 'Sample Sizes'],
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # Sleep duration
        fig.add_trace(
            go.Bar(x=timing_summary['primary_exercise_time'], 
                   y=timing_summary['night1_sleep_duration'],
                   name='Sleep Duration (hrs)',
                   marker_color='lightblue'),
            row=1, col=1
        )
        
        # Deep sleep
        fig.add_trace(
            go.Bar(x=timing_summary['primary_exercise_time'], 
                   y=timing_summary['night1_deep_sleep'],
                   name='Deep Sleep (hrs)',
                   marker_color='darkblue'),
            row=1, col=2
        )
        
        # Sleep score
        fig.add_trace(
            go.Bar(x=timing_summary['primary_exercise_time'], 
                   y=timing_summary['night1_sleep_score'],
                   name='Sleep Score',
                   marker_color='green'),
            row=2, col=1
        )
        
        # Sample sizes
        fig.add_trace(
            go.Bar(x=timing_summary['primary_exercise_time'], 
                   y=timing_summary['total_exercise_time'],
                   name='# Observations',
                   marker_color='orange'),
            row=2, col=2
        )
        
        fig.update_layout(
            title='Exercise Timing Effects on Sleep Quality',
            showlegend=False,
            height=600
        )
        
        return fig
    
    def create_exercise_sleep_scatter(self, df):
        """Create scatter plots showing exercise-sleep relationships"""
        if df.empty:
            return []
        
        plots = []
        
        # Exercise intensity vs sleep quality
        if 'exercise_intensity' in df.columns and 'night1_sleep_score' in df.columns:
            clean_data = df[['exercise_intensity', 'night1_sleep_score', 'primary_exercise_time']].dropna()
            
            if len(clean_data) > 5:
                fig = px.scatter(
                    clean_data,
                    x='exercise_intensity',
                    y='night1_sleep_score',
                    color='primary_exercise_time',
                    title='Exercise Intensity vs Sleep Score (Next Night)',
                    labels={'exercise_intensity': 'Exercise Intensity (0-1)', 
                           'night1_sleep_score': 'Sleep Score'},
                    trendline='ols'
                )
                plots.append(fig)
        
        # Exercise timing (hour) vs sleep duration
        if 'avg_exercise_hour' in df.columns and 'night1_sleep_duration' in df.columns:
            clean_data = df[['avg_exercise_hour', 'night1_sleep_duration']].dropna()
            
            if len(clean_data) > 5:
                fig = px.scatter(
                    clean_data,
                    x='avg_exercise_hour',
                    y='night1_sleep_duration',
                    title='Exercise Time of Day vs Sleep Duration (Next Night)',
                    labels={'avg_exercise_hour': 'Average Exercise Hour (24h)', 
                           'night1_sleep_duration': 'Sleep Duration (hours)'},
                    trendline='ols'
                )
                plots.append(fig)
        
        return plots
    
    def generate_insights(self, df, regression_results, timing_analysis):
        """Generate key insights from the analysis"""
        insights = []
        
        if df.empty:
            insights.append("‚ùå Insufficient data for exercise-sleep analysis.")
            return insights
        
        insights.append(f"üìä **Analysis Summary**: {len(df)} exercise sessions analyzed with sleep data.")
        
        # Timing insights
        if timing_analysis:
            best_times = []
            for metric, categories in timing_analysis.items():
                if categories:
                    best_category = max(categories.keys(), 
                                      key=lambda x: categories[x].get('effect_size', -999)
                                      if not pd.isna(categories[x].get('effect_size')) else -999)
                    best_effect = categories[best_category].get('effect_size', 0)
                    
                    if not pd.isna(best_effect):
                        metric_name = metric.replace('night1_', '').replace('_', ' ').title()
                        insights.append(f"üïê **Best time for {metric_name}**: {best_category} "
                                      f"(+{best_effect:.2f} improvement)")
        
        # Regression insights
        if regression_results:
            for target, results in regression_results.items():
                if results['linear_r2'] > 0.1:  # Meaningful relationship
                    metric_name = target.replace('night1_', '').replace('night2_', '').replace('_', ' ').title()
                    night = "first" if "night1" in target else "second"
                    
                    # Find strongest predictor
                    strongest_predictor = max(results['feature_importance'].keys(),
                                            key=lambda x: results['feature_importance'][x])
                    
                    insights.append(f"üìà **{metric_name} ({night} night)**: "
                                  f"R¬≤ = {results['linear_r2']:.3f}, "
                                  f"strongest factor: {strongest_predictor.replace('_', ' ')}")
        
        # Exercise timing effect insights
        if 'avg_exercise_hour' in df.columns:
            early_exercise = df[df['avg_exercise_hour'] < 12]
            late_exercise = df[df['avg_exercise_hour'] >= 18]
            
            if len(early_exercise) > 2 and len(late_exercise) > 2:
                early_sleep = early_exercise['night1_sleep_score'].mean()
                late_sleep = late_exercise['night1_sleep_score'].mean()
                
                if not pd.isna(early_sleep) and not pd.isna(late_sleep):
                    difference = early_sleep - late_sleep
                    if difference > 5:
                        insights.append(f"üåÖ **Early exercise benefit**: "
                                      f"Morning exercise leads to {difference:.1f} point higher sleep score")
                    elif difference < -5:
                        insights.append(f"üåô **Evening exercise benefit**: "
                                      f"Evening exercise leads to {abs(difference):.1f} point higher sleep score")
        
        return insights
</file>

<file path="src/strava_api.py">
import requests
import pandas as pd
from datetime import datetime, timedelta
import streamlit as st

class StravaAPI:
    def __init__(self, access_token):
        self.access_token = access_token
        self.base_url = 'https://www.strava.com/api/v3'
        self.headers = {'Authorization': f'Bearer {access_token}'}
    
    def get_athlete(self):
        """Get authenticated athlete's profile"""
        url = f"{self.base_url}/athlete"
        response = requests.get(url, headers=self.headers)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"Failed to get athlete data: {response.text}")
    
    def get_activities(self, before=None, after=None, page=1, per_page=30):
        """Get athlete's activities"""
        url = f"{self.base_url}/athlete/activities"
        params = {
            'page': page,
            'per_page': per_page
        }
        
        if before:
            params['before'] = int(before.timestamp())
        if after:
            params['after'] = int(after.timestamp())
        
        response = requests.get(url, headers=self.headers, params=params)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"Failed to get activities: {response.text}")
    
    def get_activity_details(self, activity_id):
        """Get detailed information about a specific activity"""
        url = f"{self.base_url}/activities/{activity_id}"
        response = requests.get(url, headers=self.headers)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"Failed to get activity details: {response.text}")
    
    def get_athlete_stats(self, athlete_id):
        """Get athlete's statistics"""
        url = f"{self.base_url}/athletes/{athlete_id}/stats"
        response = requests.get(url, headers=self.headers)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"Failed to get athlete stats: {response.text}")
    
    def activities_to_dataframe(self, activities):
        """Convert activities list to pandas DataFrame"""
        if not activities:
            return pd.DataFrame()
        
        df = pd.DataFrame(activities)
        
        # Convert datetime fields
        if 'start_date' in df.columns:
            df['start_date'] = pd.to_datetime(df['start_date'])
        if 'start_date_local' in df.columns:
            df['start_date_local'] = pd.to_datetime(df['start_date_local'])
        
        # Convert distance from meters to kilometers
        if 'distance' in df.columns:
            df['distance_km'] = df['distance'] / 1000
        
        # Convert moving time to hours
        if 'moving_time' in df.columns:
            df['moving_time_hours'] = df['moving_time'] / 3600
        
        # Calculate pace (min/km) for running activities
        if 'distance' in df.columns and 'moving_time' in df.columns:
            df['pace_min_per_km'] = (df['moving_time'] / 60) / (df['distance'] / 1000)
        
        return df
</file>

<file path="src/strava_auth.py">
import streamlit as st
import requests
import os
from urllib.parse import urlencode
from dotenv import load_dotenv

load_dotenv()

class StravaAuth:
    def __init__(self):
        self.client_id = os.getenv('STRAVA_CLIENT_ID')
        self.client_secret = os.getenv('STRAVA_CLIENT_SECRET')
        self.redirect_uri = os.getenv('STRAVA_REDIRECT_URI', 'http://localhost:8501')
        self.auth_url = 'https://www.strava.com/oauth/authorize'
        self.token_url = 'https://www.strava.com/oauth/token'
    
    def get_authorization_url(self):
        """Generate Strava OAuth authorization URL"""
        params = {
            'client_id': self.client_id,
            'response_type': 'code',
            'redirect_uri': self.redirect_uri,
            'approval_prompt': 'force',
            'scope': 'read,activity:read_all,profile:read_all'
        }
        return f"{self.auth_url}?{urlencode(params)}"
    
    def exchange_code_for_token(self, authorization_code):
        """Exchange authorization code for access token"""
        data = {
            'client_id': self.client_id,
            'client_secret': self.client_secret,
            'code': authorization_code,
            'grant_type': 'authorization_code'
        }
        
        response = requests.post(self.token_url, data=data)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"Token exchange failed: {response.text}")
    
    def refresh_token(self, refresh_token):
        """Refresh an expired access token"""
        data = {
            'client_id': self.client_id,
            'client_secret': self.client_secret,
            'refresh_token': refresh_token,
            'grant_type': 'refresh_token'
        }
        
        response = requests.post(self.token_url, data=data)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"Token refresh failed: {response.text}")
    
    def is_authenticated(self):
        """Check if user is authenticated"""
        return 'access_token' in st.session_state and st.session_state.access_token is not None
    
    def get_access_token(self):
        """Get current access token"""
        return st.session_state.get('access_token')
</file>

<file path="src/test_withings.py">
import streamlit as st
from withings_api import WithingsAPI
from datetime import datetime, timedelta

# Simple test script to debug Withings API calls
if 'withings_access_token' in st.session_state:
    api = WithingsAPI(st.session_state.withings_access_token)
    
    st.write("Testing Withings API calls...")
    
    # Test sleep data with different approaches
    end_date = datetime.now()
    start_date = end_date - timedelta(days=7)
    
    st.write(f"Testing sleep data from {start_date.date()} to {end_date.date()}")
    
    try:
        # Direct API call to see raw response
        import requests
        
        params = {
            'action': 'getsummary',
            'startdateymd': start_date.strftime('%Y-%m-%d'),
            'enddateymd': end_date.strftime('%Y-%m-%d'),
            'access_token': st.session_state.withings_access_token
        }
        
        response = requests.get('https://wbsapi.withings.net/v2/sleep', params=params)
        st.write("Raw sleep API response:")
        st.json(response.json())
        
    except Exception as e:
        st.error(f"Error: {str(e)}")
else:
    st.write("Please connect to Withings first")
</file>

<file path="src/token_storage.py">
import json
import os
from datetime import datetime

class TokenStorage:
    def __init__(self, storage_file='tokens.json'):
        self.storage_file = storage_file
    
    def save_tokens(self, service, tokens):
        """Save tokens to file"""
        try:
            # Load existing tokens
            if os.path.exists(self.storage_file):
                with open(self.storage_file, 'r') as f:
                    all_tokens = json.load(f)
            else:
                all_tokens = {}
            
            # Add timestamp
            tokens['saved_at'] = datetime.now().isoformat()
            
            # Save service tokens
            all_tokens[service] = tokens
            
            # Write back to file
            with open(self.storage_file, 'w') as f:
                json.dump(all_tokens, f, indent=2)
            
            return True
        except Exception as e:
            print(f"Error saving tokens: {e}")
            return False
    
    def load_tokens(self, service):
        """Load tokens from file"""
        try:
            if not os.path.exists(self.storage_file):
                return None
            
            with open(self.storage_file, 'r') as f:
                all_tokens = json.load(f)
            
            return all_tokens.get(service)
        except Exception as e:
            print(f"Error loading tokens: {e}")
            return None
    
    def clear_tokens(self, service=None):
        """Clear tokens for a service or all tokens"""
        try:
            if not os.path.exists(self.storage_file):
                return True
            
            if service is None:
                # Clear all tokens
                os.remove(self.storage_file)
                return True
            
            # Clear specific service
            with open(self.storage_file, 'r') as f:
                all_tokens = json.load(f)
            
            if service in all_tokens:
                del all_tokens[service]
            
            with open(self.storage_file, 'w') as f:
                json.dump(all_tokens, f, indent=2)
            
            return True
        except Exception as e:
            print(f"Error clearing tokens: {e}")
            return False
    
    def is_authenticated(self, service):
        """Check if service is authenticated"""
        tokens = self.load_tokens(service)
        return tokens is not None and 'access_token' in tokens
    
    def get_access_token(self, service):
        """Get access token for service"""
        tokens = self.load_tokens(service)
        if tokens:
            return tokens.get('access_token')
        return None
</file>

<file path="src/withings_api.py">
import requests
import pandas as pd
from datetime import datetime, timedelta
import streamlit as st

class WithingsAPI:
    def __init__(self, access_token):
        self.access_token = access_token
        self.base_url = 'https://wbsapi.withings.net'
        
    def make_request(self, endpoint, params=None):
        """Make authenticated request to Withings API"""
        if params is None:
            params = {}
        
        params['access_token'] = self.access_token
        
        response = requests.get(f"{self.base_url}{endpoint}", params=params)
        
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 0:  # Success
                return data.get('body', {})
            else:
                raise Exception(f"API error: {data.get('error', 'Unknown error')}")
        else:
            raise Exception(f"HTTP error: {response.status_code} - {response.text}")
    
    def get_user_info(self):
        """Get user profile information"""
        return self.make_request('/v2/user', {'action': 'getdevice'})
    
    def get_weight_measurements(self, start_date=None, end_date=None):
        """Get weight and body composition measurements"""
        params = {
            'action': 'getmeas',
            'category': 1,  # Real measurements only
            'meastypes': '1,5,6,8,76,77,88,91,123'  # Weight, fat %, muscle %, bone %, BMI, fat mass, muscle mass, bone mass, metabolic age
        }
        
        if start_date:
            params['startdate'] = int(start_date.timestamp())
        if end_date:
            params['enddate'] = int(end_date.timestamp())
        
        try:
            data = self.make_request('/measure', params)
            return data.get('measuregrps', [])
        except Exception as e:
            st.warning(f"Could not fetch weight data: {str(e)}")
            return []
    
    def get_sleep_data(self, start_date=None, end_date=None):
        """Get sleep measurements"""
        # Ensure we have date parameters (Withings requires them)
        if not start_date:
            start_date = datetime.now() - timedelta(days=30)
        if not end_date:
            end_date = datetime.now()
        
        # Try the sleep summary endpoint first (more reliable)
        params = {
            'action': 'getsummary',
            'startdateymd': start_date.strftime('%Y-%m-%d'),
            'enddateymd': end_date.strftime('%Y-%m-%d')
        }
        
        try:
            print(f"Sleep API params: {params}")  # Debug
            data = self.make_request('/v2/sleep', params)
            return data.get('series', [])
        except Exception as e:
            print(f"Sleep summary API error: {str(e)}")  # Debug
            
            # Try the detailed sleep endpoint
            try:
                detail_params = {
                    'action': 'get',
                    'startdateymd': start_date.strftime('%Y-%m-%d'),
                    'enddateymd': end_date.strftime('%Y-%m-%d')
                }
                
                print(f"Trying detailed sleep params: {detail_params}")  # Debug
                data = self.make_request('/v2/sleep', detail_params)
                return data.get('series', [])
            except Exception as e2:
                print(f"Detailed sleep API error: {str(e2)}")  # Debug
                
                # If both fail, try without date range (last 30 days default)
                try:
                    fallback_params = {'action': 'getsummary'}
                    print(f"Trying fallback sleep params: {fallback_params}")  # Debug
                    data = self.make_request('/v2/sleep', fallback_params)
                    return data.get('series', [])
                except Exception as e3:
                    print(f"Fallback sleep API error: {str(e3)}")  # Debug
                    st.warning("Could not fetch sleep data. This may be due to: no sleep tracking device connected, insufficient permissions, or no sleep data available for the selected period.")
                    return []
    
    def get_activity_data(self, start_date=None, end_date=None):
        """Get activity/steps data"""
        params = {
            'action': 'getmeas',
            'category': 1,
            'meastypes': '36,40'  # Steps, active calories
        }
        
        if start_date:
            params['startdate'] = int(start_date.timestamp())
        if end_date:
            params['enddate'] = int(end_date.timestamp())
        
        try:
            data = self.make_request('/measure', params)
            return data.get('measuregrps', [])
        except Exception as e:
            st.warning(f"Could not fetch activity data: {str(e)}")
            return []
    
    def weight_to_dataframe(self, weight_data):
        """Convert weight measurements to pandas DataFrame"""
        if not weight_data:
            return pd.DataFrame()
        
        records = []
        for group in weight_data:
            date = datetime.fromtimestamp(group['date'])
            record = {'date': date}
            
            for measure in group['measures']:
                measure_type = measure['type']
                value = measure['value'] * (10 ** measure['unit'])
                
                # Map measure types to readable names
                type_mapping = {
                    1: 'weight',
                    5: 'fat_percent',
                    6: 'muscle_percent', 
                    8: 'bone_percent',
                    76: 'muscle_mass',
                    77: 'bone_mass',
                    88: 'fat_mass',
                    91: 'bmi',
                    123: 'metabolic_age'
                }
                
                if measure_type in type_mapping:
                    record[type_mapping[measure_type]] = value
            
            records.append(record)
        
        df = pd.DataFrame(records)
        if not df.empty:
            df = df.sort_values('date')
            df = df.reset_index(drop=True)
        
        return df
    
    def sleep_to_dataframe(self, sleep_data):
        """Convert sleep data to pandas DataFrame"""
        if not sleep_data:
            return pd.DataFrame()
        
        records = []
        for sleep_session in sleep_data:
            date = datetime.fromtimestamp(sleep_session['startdate'])
            
            record = {
                'date': date,
                'sleep_duration': sleep_session.get('data', {}).get('durationtosleep', 0) / 60,  # minutes to hours
                'deep_sleep': sleep_session.get('data', {}).get('deepsleepduration', 0) / 60,
                'light_sleep': sleep_session.get('data', {}).get('lightsleepduration', 0) / 60,
                'rem_sleep': sleep_session.get('data', {}).get('remsleepduration', 0) / 60,
                'wake_duration': sleep_session.get('data', {}).get('wakeupcount', 0),
                'sleep_score': sleep_session.get('data', {}).get('sleep_score', 0)
            }
            
            records.append(record)
        
        df = pd.DataFrame(records)
        if not df.empty:
            df = df.sort_values('date')
            df = df.reset_index(drop=True)
        
        return df
    
    def activity_to_dataframe(self, activity_data):
        """Convert activity data to pandas DataFrame"""
        if not activity_data:
            return pd.DataFrame()
        
        records = []
        for group in activity_data:
            date = datetime.fromtimestamp(group['date'])
            record = {'date': date}
            
            for measure in group['measures']:
                measure_type = measure['type']
                value = measure['value'] * (10 ** measure['unit'])
                
                if measure_type == 36:  # Steps
                    record['steps'] = value
                elif measure_type == 40:  # Active calories
                    record['active_calories'] = value
            
            records.append(record)
        
        df = pd.DataFrame(records)
        if not df.empty:
            df = df.sort_values('date')
            df = df.reset_index(drop=True)
        
        return df
</file>

<file path="src/withings_auth.py">
import streamlit as st
import requests
import os
import hashlib
import base64
import secrets
from urllib.parse import urlencode, parse_qs, urlparse
from dotenv import load_dotenv

load_dotenv()

class WithingsAuth:
    def __init__(self):
        self.client_id = os.getenv('WITHINGS_CLIENT_ID')
        self.client_secret = os.getenv('WITHINGS_CLIENT_SECRET')
        self.redirect_uri = os.getenv('WITHINGS_REDIRECT_URI', 'http://localhost:8501')
        self.auth_url = 'https://account.withings.com/oauth2_user/authorize2'
        self.token_url = 'https://wbsapi.withings.net/v2/oauth2'
        self.scope = 'user.metrics,user.activity,user.sleepevents'
    
    def generate_code_verifier(self):
        """Generate code verifier for PKCE"""
        code_verifier = base64.urlsafe_b64encode(secrets.token_bytes(32)).decode('utf-8')
        # Remove padding
        return code_verifier.rstrip('=')
    
    def generate_code_challenge(self, code_verifier):
        """Generate code challenge from verifier"""
        digest = hashlib.sha256(code_verifier.encode('utf-8')).digest()
        return base64.urlsafe_b64encode(digest).decode('utf-8').rstrip('=')
    
    def get_authorization_url(self):
        """Generate Withings OAuth authorization URL"""
        if not self.client_id:
            raise Exception("Withings Client ID not found in environment variables")
        
        # Simplified OAuth without PKCE
        state = secrets.token_urlsafe(32)
        
        # Store in session state for later use
        st.session_state.withings_state = state
        
        params = {
            'response_type': 'code',
            'client_id': self.client_id,
            'redirect_uri': self.redirect_uri,
            'scope': self.scope,
            'state': state
        }
        
        # Debug info (remove in production)
        print(f"Auth URL params: {params}")
        
        return f"{self.auth_url}?{urlencode(params)}"
    
    def exchange_code_for_token(self, authorization_code, state):
        """Exchange authorization code for access token"""
        # Use the correct Withings token exchange format
        
        data = {
            'action': 'requesttoken',
            'grant_type': 'authorization_code',
            'client_id': self.client_id,
            'client_secret': self.client_secret,
            'code': authorization_code,
            'redirect_uri': self.redirect_uri
        }
        
        print(f"Token exchange data: {data}")  # Debug
        
        response = requests.post(self.token_url, data=data)
        
        print(f"Response status: {response.status_code}")  # Debug
        print(f"Response text: {response.text}")  # Debug
        
        if response.status_code == 200:
            token_data = response.json()
            if token_data.get('status') == 0 and 'body' in token_data:
                # Withings API returns data in 'body' field
                body = token_data['body']
                if 'access_token' in body:
                    return body
                else:
                    raise Exception(f"Token exchange failed: {token_data}")
            elif token_data.get('status') == 601:
                # Rate limit error
                wait_time = token_data.get('body', {}).get('wait_seconds', 10)
                raise Exception(f"Rate limited by Withings. Please wait {wait_time} seconds and try again.")
            else:
                raise Exception(f"Token exchange failed: {token_data}")
        else:
            raise Exception(f"Token exchange failed: {response.text}")
    
    def refresh_token(self, refresh_token):
        """Refresh an expired access token"""
        data = {
            'action': 'requesttoken',
            'grant_type': 'refresh_token',
            'client_id': self.client_id,
            'client_secret': self.client_secret,
            'refresh_token': refresh_token
        }
        
        response = requests.post(self.token_url, data=data)
        
        if response.status_code == 200:
            token_data = response.json()
            if token_data.get('status') == 0 and 'body' in token_data:
                body = token_data['body']
                if 'access_token' in body:
                    return body
                else:
                    raise Exception(f"Token refresh failed: {token_data}")
            else:
                raise Exception(f"Token refresh failed: {token_data}")
        else:
            raise Exception(f"Token refresh failed: {response.text}")
    
    def is_authenticated(self):
        """Check if user is authenticated with Withings"""
        return ('withings_access_token' in st.session_state and 
                st.session_state.withings_access_token is not None)
    
    def get_access_token(self):
        """Get current Withings access token"""
        return st.session_state.get('withings_access_token')
</file>

<file path="jira-confluence-analyzer-todo.md">
# Strava Data Analyzer - Todo List

## High Priority Tasks

- [ ] Test the application with real Strava and Withings data

## Medium Priority Tasks

- [ ] Implement performance analytics (personal records, training zones)

## Low Priority Tasks

- [ ] Implement caching to improve performance
- [ ] Add segment analysis and leaderboards
- [ ] Create training load and recovery metrics

## Completed Tasks

- [x] Set up Streamlit project structure and virtual environment
- [x] Research and configure Strava API authentication (OAuth 2.0)
- [x] Register application with Strava to get API credentials
- [x] Install required dependencies (streamlit, requests, pandas, plotly/matplotlib, scipy)
- [x] Create Strava data fetching module (activities, athlete data, segments)
- [x] Design main Streamlit UI with sidebar navigation
- [x] Implement activity analytics dashboard (distance, pace, elevation trends)
- [x] Add error handling and user feedback for API failures
- [x] Add configuration file for API endpoints and settings
- [x] Implement athlete profile and stats display
- [x] Add data filtering and date range selection functionality
- [x] Create data export functionality (CSV, Excel)
- [x] Add comprehensive yearly and seasonal exercise analysis
- [x] Research Withings API for weight and sleep data
- [x] Implement Withings OAuth authentication
- [x] Create Withings data fetching module (weight, sleep)
- [x] Implement correlation analysis between exercise, sleep, and weight
- [x] Add correlation visualization dashboard

---

**Project Notes:**
- This is a Streamlit application for analyzing Strava fitness data
- Focus on getting core functionality working before adding advanced features
- Remember to handle API rate limits (100 requests per 15 minutes, 1000 per day)
- Strava uses OAuth 2.0 for authentication
</file>

<file path="README.md">
# Strava Data Analyzer

A Streamlit application for analyzing your Strava fitness data.

## Setup

1. Activate virtual environment:
   ```bash
   source strava_env/bin/activate
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Configure Strava API credentials in `.env` file

4. Run the application:
   ```bash
   streamlit run src/app.py
   ```

## Features

- Activity analytics (distance, pace, elevation trends)
- Performance metrics and personal records
- Training zone analysis
- Data export capabilities
</file>

<file path="requirements.txt">
streamlit>=1.28.0
requests>=2.31.0
pandas>=2.0.0
plotly>=5.15.0
python-dotenv>=1.0.0
stravalib>=1.4.0
scipy>=1.10.0
</file>

</files>
